{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Hwloc ─ v1.0.3\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/Repos/advection-diffusion-catalysis/Project.toml`\n",
      " \u001b[90m [0e44f5e4]\u001b[39m\u001b[92m + Hwloc v1.0.3\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/Repos/advection-diffusion-catalysis/Manifest.toml`\n",
      " \u001b[90m [0e44f5e4]\u001b[39m\u001b[92m + Hwloc v1.0.3\u001b[39m\n",
      "\u001b[32m\u001b[1m   Building\u001b[22m\u001b[39m Hwloc → `~/.julia/packages/Hwloc/1kB0k/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"Hwloc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Hwloc [0e44f5e4-bd66-52a0-8798-143a42290a1d]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Hwloc\n",
    "Hwloc.num_physical_cores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using .Threads\n",
    "nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base.Threads.@spawn\n",
    "using DrWatson\n",
    "@quickactivate :Catalyst\n",
    "using BenchmarkTools\n",
    "\n",
    "function benchmark_distributed_evaluation(parameters,N)\n",
    "    errors = zeros(N) # init model errors\n",
    "    # we need to read the experiment data in this block\n",
    "    input_exp = Float64[]\n",
    "    output_exp = Float64[]\n",
    "    for row in CSV.File(datadir(\"experiment/new-data.csv\"); delim = \" \")\n",
    "        push!(input_exp, row.I)\n",
    "        push!(output_exp, row.O)\n",
    "    end\n",
    "    # done reading \n",
    "\n",
    "    F = Array{Task}(undef,N)\n",
    "     for i in 1:N\n",
    "        F[i] = @spawn (Catalyst.solve(parameters[1], parameters[2], 1.,\n",
    "                                      input_exp, output_exp, progress=false, \n",
    "                                      microcomp_type=:nonlinear,\n",
    "                                      Q=parameters[3], kₙ=parameters[4],\n",
    "                                      calibration=true))# save the model error\n",
    "     end\n",
    "        for i in 1:N\n",
    "        errors[i] = fetch(F[i])\n",
    "        end\n",
    "    return errors\n",
    "end\n",
    "\n",
    "parameters = [1e-4, 1., 1., 10.]\n",
    "@time benchmark_distributed_evaluation(parameters, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  3.03 KiB\n",
       "  allocs estimate:  22\n",
       "  --------------\n",
       "  minimum time:     6.250 μs (0.00% GC)\n",
       "  median time:      15.495 μs (0.00% GC)\n",
       "  mean time:        16.088 μs (0.00% GC)\n",
       "  maximum time:     162.071 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads.@spawn \n",
    "using BenchmarkTools\n",
    "function benchmark_threading_dummy(N)\n",
    "errors = zeros(N)\n",
    "F = Array{Task}(undef,N)\n",
    "for i in 1:N\n",
    "    F[i] = @spawn 10+10\n",
    "end\n",
    "for i in 1:N\n",
    "    errors[i]= fetch(F[i])\n",
    "end \n",
    "return errors\n",
    "end \n",
    "@benchmark benchmark_threading_dummy(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.Threads.nthreads()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.34 KiB\n",
       "  allocs estimate:  52\n",
       "  --------------\n",
       "  minimum time:     10.116 μs (0.00% GC)\n",
       "  median time:      22.277 μs (0.00% GC)\n",
       "  mean time:        23.483 μs (2.11% GC)\n",
       "  maximum time:     5.055 ms (97.96% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads.@spawn \n",
    "using BenchmarkTools\n",
    "function benchmark_threading_dummy(N)\n",
    "errors = zeros(N)\n",
    "F = Array{Task}(undef,N)\n",
    "for i in 1:N\n",
    "    F[i] = @spawn 10+10\n",
    "end\n",
    "for i in 1:N\n",
    "    errors[i]= fetch(F[i])\n",
    "end \n",
    "return errors\n",
    "end \n",
    "@benchmark benchmark_threading_dummy(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  112 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     40.514 ns (0.00% GC)\n",
       "  median time:      43.803 ns (0.00% GC)\n",
       "  mean time:        52.652 ns (9.76% GC)\n",
       "  maximum time:     2.359 μs (97.09% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     990"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads.@spawn \n",
    "using BenchmarkTools\n",
    "function benchmark_serial_dummy(N)\n",
    "errors = zeros(N)\n",
    "for i in 1:N\n",
    "    errors[i]= 10+10\n",
    "end \n",
    "return errors\n",
    "end \n",
    "@benchmark benchmark_serial_dummy(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  896 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     147.982 ns (0.00% GC)\n",
       "  median time:      186.101 ns (0.00% GC)\n",
       "  mean time:        231.410 ns (14.36% GC)\n",
       "  maximum time:     9.131 μs (93.55% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     870"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads.@spawn \n",
    "using BenchmarkTools\n",
    "function benchmark_serial_dummy(N)\n",
    "errors = zeros(N)\n",
    "for i in 1:N\n",
    "    errors[i]= 10+10\n",
    "end \n",
    "return errors\n",
    "end \n",
    "@benchmark benchmark_serial_dummy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  72.06 KiB\n",
       "  allocs estimate:  502\n",
       "  --------------\n",
       "  minimum time:     84.908 μs (0.00% GC)\n",
       "  median time:      124.793 μs (0.00% GC)\n",
       "  mean time:        131.006 μs (5.00% GC)\n",
       "  maximum time:     6.882 ms (96.21% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads.@spawn \n",
    "using BenchmarkTools\n",
    "function benchmark_threading_dummy(N)\n",
    "errors = zeros(N)\n",
    "F = Array{Task}(undef,N)\n",
    "for i in 1:N\n",
    "    F[i] = @spawn 10+10\n",
    "end\n",
    "for i in 1:N\n",
    "    errors[i]= fetch(F[i])\n",
    "end \n",
    "return errors\n",
    "end \n",
    "@benchmark benchmark_threading_dummy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  8.05 KiB\n",
       "  allocs estimate:  54\n",
       "  --------------\n",
       "  minimum time:     33.318 μs (0.00% GC)\n",
       "  median time:      54.354 μs (0.00% GC)\n",
       "  mean time:        53.803 μs (2.11% GC)\n",
       "  maximum time:     11.607 ms (97.98% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using .Threads\n",
    "using BenchmarkTools\n",
    "function benchmark_serial_dummy(N)\n",
    "errors = zeros(N)\n",
    "@inbounds @threads  for i in 1:N\n",
    "    errors[i]= 10+10\n",
    "end \n",
    "return errors\n",
    "end \n",
    "@benchmark benchmark_serial_dummy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
